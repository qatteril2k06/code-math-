def word_counter(goal_dir: str, filenames: list):
    import pymorphy2
    from pymystem3 import Mystem

    morph = pymorphy2.MorphAnalyzer()
    mystem = Mystem()

    words_blacklist = ['–º–æ–π', '—Ç–≤–æ–π', '—Å–≤–æ–π', '–Ω–∞—à', '–≤–∞—à', '–µ–≥–æ', '–µ—ë', '–∏—Ö',
                       '—Å–∞–º', '—Å–∞–º—ã–π', '–≤–µ—Å—å', '–≤—Å—è–∫–∏–π', '–∫–∞–∂–¥—ã–π', '–ª—é–±–æ–π', '–¥—Ä—É–≥–æ–π', '–∏–Ω–æ–π',
                       '–≤—Å—è—á–µ—Å–∫–∏–π', '–≤—Å—è–∫', '—Ç–æ—Ç', '—ç—Ç–æ—Ç', '—Ç–∞–∫–æ–π', '—Ç–∞–∫–æ–≤', '—Å–µ–π', '–æ–Ω—ã–π',
                       '–∫–∞–∫–æ–π', '–∫–æ—Ç–æ—Ä—ã–π', '—á–µ–π', '–Ω–∏–∫–∞–∫–æ–π', '–Ω–∏—á–µ–π', '–Ω–µ–∫–æ—Ç–æ—Ä—ã–π', '–Ω–µ–∫–∏–π', '–∫–∞–∫–æ–π-—Ç–æ',
                       '–º–æ—á—å']
    words_whitelist = ['—Å–ø–∞—Å–∏–±–æ', '–ø–æ–º–æ—á—å']
    tags_blacklist = ['PREP', 'CONJ', 'PRCL']
    tags_whitelist = ['NOUN', 'VERB', 'ADJF']

    def text_modifier(filenames_list: list) -> list:
        break_symbol = '‚òé'
        all_lines = ''
        for filename in filenames_list:
            filename = str(filename)
            # if '.txt' not in filename:
            #     filename += '.txt'
            with open(goal_dir + filename, 'r', encoding='UTF8') as text_file:
                a = [line.strip().upper() for line in text_file.readlines()]
                chars_to_check = chars_finder(filename)
                for line in range(len(a)):
                    for char in chars_to_check:
                        a[line] = a[line].replace(char, ' ')
                    all_lines += a[line] + ' '
            all_lines += break_symbol
        all_lines = ' '.join(mystem.lemmatize(all_lines.replace('–ü–û–ú–û–ß–¨', 'üÜò'))).replace('üÜò', '–ø–æ–º–æ—á—å')
        return all_lines.split(break_symbol)[:-1]

    def chars_finder(filename: str) -> set:
        chars_to_check = set()
        path = 'docs/utf8/'
        with open(path + filename, 'r', encoding='UTF8') as text_file:
            a = [line.strip().upper() for line in text_file.readlines()]
            for line in range(len(a)):
                for char in a[line]:
                    if not char.isalpha():
                        chars_to_check.add(char)
        return chars_to_check

    def word_checker(word: str) -> bool:
        if word in words_whitelist:
            return True
        if all([65 <= ord(i) <= 90 for i in word]) and len(word) > 1:
            return True
        if not word.isalpha():
            return False
        if word in words_blacklist:
            return False
        tag = morph.parse(word)[0].tag.POS
        if tag in tags_blacklist or tag not in tags_whitelist:
            return False
        return True

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–≤–∞ –≤ —Ñ–∞–π–ª–µ
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å word: count
    def word_counts(file_text: str) -> dict:
        words = {}
        all_words_in_file = file_text.split()
        for word in all_words_in_file:
            if word_checker(word):
                word = word.upper()
                try:
                    words[word] += 1
                except KeyError:
                    words[word] = 1

        # –ó–¥–µ—Å—å –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –Ω–æ –ø–æ–∫–∞ –æ—Ç–∫–∞–∂–µ–º—Å—è –æ—Ç —ç—Ç–æ–π –∏–¥–µ–∏
        # words_count = sum([i for i in words.values()])
        # for word in words.keys():
        #     words[word][1] = words[word][0] / words_count

        return words

    file_number = 0
    for text in text_modifier(filenames):
        result = word_counts(text)
        yield result, filenames[file_number]
        file_number += 1
